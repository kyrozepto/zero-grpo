{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 - Reward Distribution Analysis\n",
                "\n",
                "Objective: Understand reward statistics on a validation set of multi-view samples.\n",
                "\n",
                "## Expected Distributions\n",
                "- R_warp: Mean ~0.7, Std ~0.15\n",
                "- R_epi: Mean ~0.8, Std ~0.12\n",
                "- R_sem: Mean ~0.85, Std ~0.10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "\n",
                "from src.rewards import CompositeReward\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize composite reward\n",
                "reward_fn = CompositeReward(device=device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Generate Validation Set\n",
                "\n",
                "Generate 500 synthetic multi-view samples with varying quality levels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_varied_samples(n_samples=500, seed=42):\n",
                "    \"\"\"\n",
                "    Generate samples with varying degrees of consistency.\n",
                "    \"\"\"\n",
                "    torch.manual_seed(seed)\n",
                "    \n",
                "    samples = []\n",
                "    conditions = []\n",
                "    \n",
                "    for i in range(n_samples):\n",
                "        H, W = 320, 320\n",
                "        \n",
                "        # Create base pattern\n",
                "        base = torch.randn(3, H, W) * 0.2 + 0.5\n",
                "        base = torch.clamp(base, 0, 1)\n",
                "        \n",
                "        # Varying consistency level (0 = inconsistent, 1 = fully consistent)\n",
                "        consistency = np.random.uniform(0.3, 1.0)\n",
                "        \n",
                "        views = []\n",
                "        for v in range(6):\n",
                "            # Mix of base and random pattern\n",
                "            random_pattern = torch.randn(3, H, W) * 0.2 + 0.5\n",
                "            random_pattern = torch.clamp(random_pattern, 0, 1)\n",
                "            \n",
                "            view = consistency * base + (1 - consistency) * random_pattern\n",
                "            view = torch.clamp(view, 0, 1)\n",
                "            views.append(view)\n",
                "        \n",
                "        views = torch.stack(views)\n",
                "        samples.append(views)\n",
                "        conditions.append(base)\n",
                "    \n",
                "    return torch.stack(samples), torch.stack(conditions)\n",
                "\n",
                "print(\"Generating 500 validation samples...\")\n",
                "samples, conditions = generate_varied_samples(500)\n",
                "print(f\"Samples shape: {samples.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Compute Rewards"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "\n",
                "for i in tqdm(range(len(samples)), desc=\"Computing rewards\"):\n",
                "    sample = samples[i:i+1].to(device)\n",
                "    condition = conditions[i:i+1].to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        result = reward_fn.forward(sample, condition, step=5000)\n",
                "    \n",
                "    results.append({\n",
                "        'sample_id': i,\n",
                "        'r_warp': result['warp'].cpu().item(),\n",
                "        'r_epi': result['epipolar'].cpu().item(),\n",
                "        'r_sem': result['semantic'].cpu().item(),\n",
                "        'r_total': result['total'].cpu().item(),\n",
                "        'r_geom': result['geometric'].cpu().item()\n",
                "    })\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "print(\"\\nReward statistics:\")\n",
                "display(df.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Distribution Histograms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
                "\n",
                "columns = ['r_warp', 'r_epi', 'r_sem', 'r_total']\n",
                "titles = ['R_warp (Depth Warping)', 'R_epi (Epipolar)', 'R_sem (Semantic)', 'R_total (Combined)']\n",
                "\n",
                "for ax, col, title in zip(axes.flat, columns, titles):\n",
                "    ax.hist(df[col], bins=30, edgecolor='black', alpha=0.7)\n",
                "    ax.axvline(df[col].mean(), color='red', linestyle='--', label=f'Mean: {df[col].mean():.3f}')\n",
                "    ax.axvline(df[col].median(), color='green', linestyle='--', label=f'Median: {df[col].median():.3f}')\n",
                "    ax.set_title(title)\n",
                "    ax.set_xlabel('Reward Value')\n",
                "    ax.set_ylabel('Frequency')\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.suptitle('Reward Distributions (500 Samples)', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/reward_distributions.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Correlation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute correlation matrix\n",
                "reward_cols = ['r_warp', 'r_epi', 'r_sem', 'r_total', 'r_geom']\n",
                "corr_matrix = df[reward_cols].corr()\n",
                "\n",
                "# Plot heatmap\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
                "            vmin=-1, vmax=1, fmt='.3f')\n",
                "plt.title('Reward Component Correlations')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/reward_correlations.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nCorrelation Matrix:\")\n",
                "display(corr_matrix)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Scatter Plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "# R_warp vs R_epi\n",
                "axes[0].scatter(df['r_warp'], df['r_epi'], alpha=0.5, s=10)\n",
                "axes[0].set_xlabel('R_warp')\n",
                "axes[0].set_ylabel('R_epi')\n",
                "axes[0].set_title('Geometric Components')\n",
                "\n",
                "# R_geom vs R_sem\n",
                "axes[1].scatter(df['r_geom'], df['r_sem'], alpha=0.5, s=10)\n",
                "axes[1].set_xlabel('R_geom')\n",
                "axes[1].set_ylabel('R_sem')\n",
                "axes[1].set_title('Geometric vs Semantic')\n",
                "\n",
                "# R_total distribution by R_sem quantile\n",
                "df['sem_quantile'] = pd.qcut(df['r_sem'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
                "for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
                "    subset = df[df['sem_quantile'] == q]\n",
                "    axes[2].hist(subset['r_total'], bins=20, alpha=0.5, label=f'{q}')\n",
                "axes[2].set_xlabel('R_total')\n",
                "axes[2].set_ylabel('Frequency')\n",
                "axes[2].set_title('R_total by R_sem Quartile')\n",
                "axes[2].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/reward_scatter_plots.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Outlier Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify outliers (extreme low rewards)\n",
                "low_total = df[df['r_total'] < df['r_total'].quantile(0.05)]\n",
                "print(f\"\\nSamples with very low R_total (bottom 5%): {len(low_total)}\")\n",
                "display(low_total.head(10))\n",
                "\n",
                "# High performers\n",
                "high_total = df[df['r_total'] > df['r_total'].quantile(0.95)]\n",
                "print(f\"\\nSamples with very high R_total (top 5%): {len(high_total)}\")\n",
                "display(high_total.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to CSV\n",
                "df.to_csv('../results/reward_statistics.csv', index=False)\n",
                "print(\"Saved reward statistics to ../results/reward_statistics.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}