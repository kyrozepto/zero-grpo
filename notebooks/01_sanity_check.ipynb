{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Sanity Check: Reward Function Validation\n",
    "\n",
    "Objective: Verify that reward components correctly differentiate between \"good\" (geometrically consistent) and \"bad\" (Janus problem, texture drift) multi-view samples.\n",
    "\n",
    "## Expected Results\n",
    "- R_warp: Good > Bad (p < 0.01)\n",
    "- R_epi: Good > Bad (p < 0.01)\n",
    "- R_sem: Good > Bad (p < 0.05)\n",
    "- R_total: Good > Bad (p < 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install torch torchvision transformers kornia scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.rewards import (\n",
    "    DepthWarpingReward,\n",
    "    EpipolarReward,\n",
    "    SemanticReward,\n",
    "    CompositeReward\n",
    ")\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all reward components\n",
    "print(\"Loading reward models...\")\n",
    "\n",
    "depth_reward = DepthWarpingReward(device=device)\n",
    "epipolar_reward = EpipolarReward(device=device)\n",
    "semantic_reward = SemanticReward(device=device)\n",
    "composite_reward = CompositeReward(device=device)\n",
    "\n",
    "print(\"All models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Test Data\n",
    "\n",
    "For sanity checking, we create:\n",
    "- **Good samples**: Consistent multi-view (same object appearance across views)\n",
    "- **Bad samples**: Inconsistent views (simulating Janus problem with random variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_consistent_samples(n_samples=25, seed=42):\n",
    "    \"\"\"\n",
    "    Generate 'good' samples with consistent appearance across views.\n",
    "    Creates a base image and applies minor viewpoint-appropriate variations.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    samples = []\n",
    "    conditions = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Create a base \"object\" pattern\n",
    "        H, W = 320, 320\n",
    "        base = torch.randn(3, H, W) * 0.2 + 0.5\n",
    "        base = torch.clamp(base, 0, 1)\n",
    "        \n",
    "        # Add a central object-like structure\n",
    "        y, x = torch.meshgrid(torch.linspace(-1, 1, H), torch.linspace(-1, 1, W), indexing='ij')\n",
    "        r = torch.sqrt(x**2 + y**2)\n",
    "        mask = (r < 0.5).float()\n",
    "        \n",
    "        for c in range(3):\n",
    "            base[c] = base[c] * (1 - mask * 0.5) + mask * (0.3 + 0.4 * c / 2)\n",
    "        \n",
    "        # Create 6 views with small consistent variations\n",
    "        views = []\n",
    "        for v in range(6):\n",
    "            # Small intensity shift (simulating lighting change)\n",
    "            shift = 0.02 * (v - 2.5)\n",
    "            view = torch.clamp(base + shift, 0, 1)\n",
    "            views.append(view)\n",
    "        \n",
    "        views = torch.stack(views)  # (6, 3, H, W)\n",
    "        samples.append(views)\n",
    "        conditions.append(base)\n",
    "    \n",
    "    return torch.stack(samples), torch.stack(conditions)\n",
    "\n",
    "\n",
    "def generate_inconsistent_samples(n_samples=25, seed=123):\n",
    "    \"\"\"\n",
    "    Generate 'bad' samples with Janus-like inconsistencies.\n",
    "    Each view has different random appearance.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    samples = []\n",
    "    conditions = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        H, W = 320, 320\n",
    "        condition = torch.randn(3, H, W) * 0.2 + 0.5\n",
    "        condition = torch.clamp(condition, 0, 1)\n",
    "        \n",
    "        # Create 6 views with LARGE inconsistent variations\n",
    "        views = []\n",
    "        for v in range(6):\n",
    "            # Random texture per view (Janus problem simulation)\n",
    "            random_texture = torch.randn(3, H, W) * 0.3 + 0.5\n",
    "            view = torch.clamp(random_texture, 0, 1)\n",
    "            views.append(view)\n",
    "        \n",
    "        views = torch.stack(views)\n",
    "        samples.append(views)\n",
    "        conditions.append(condition)\n",
    "    \n",
    "    return torch.stack(samples), torch.stack(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "print(\"Generating synthetic test data...\")\n",
    "\n",
    "good_samples, good_conditions = generate_consistent_samples(25)\n",
    "bad_samples, bad_conditions = generate_inconsistent_samples(25)\n",
    "\n",
    "print(f\"Good samples shape: {good_samples.shape}\")\n",
    "print(f\"Bad samples shape: {bad_samples.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Rewards for All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rewards_batch(samples, conditions, composite):\n",
    "    \"\"\"\n",
    "    Compute all reward components for a batch of samples.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'warp': [],\n",
    "        'epipolar': [],\n",
    "        'semantic': [],\n",
    "        'total': []\n",
    "    }\n",
    "    \n",
    "    for i in tqdm(range(len(samples)), desc=\"Computing rewards\"):\n",
    "        sample = samples[i:i+1].to(device)\n",
    "        condition = conditions[i:i+1].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            result = composite.forward(sample, condition, step=5000)\n",
    "        \n",
    "        results['warp'].append(result['warp'].cpu().item())\n",
    "        results['epipolar'].append(result['epipolar'].cpu().item())\n",
    "        results['semantic'].append(result['semantic'].cpu().item())\n",
    "        results['total'].append(result['total'].cpu().item())\n",
    "    \n",
    "    return {k: np.array(v) for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rewards\n",
    "print(\"Computing rewards for good samples...\")\n",
    "good_rewards = compute_rewards_batch(good_samples, good_conditions, composite_reward)\n",
    "\n",
    "print(\"\\nComputing rewards for bad samples...\")\n",
    "bad_rewards = compute_rewards_batch(bad_samples, bad_conditions, composite_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistical_tests(good, bad):\n",
    "    \"\"\"\n",
    "    Perform t-tests and compute effect sizes.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for key in ['warp', 'epipolar', 'semantic', 'total']:\n",
    "        # Two-sample t-test\n",
    "        t_stat, p_value = stats.ttest_ind(good[key], bad[key])\n",
    "        \n",
    "        # Cohen's d effect size\n",
    "        pooled_std = np.sqrt(((len(good[key])-1)*np.std(good[key])**2 + \n",
    "                              (len(bad[key])-1)*np.std(bad[key])**2) / \n",
    "                             (len(good[key]) + len(bad[key]) - 2))\n",
    "        cohens_d = (np.mean(good[key]) - np.mean(bad[key])) / pooled_std if pooled_std > 0 else 0\n",
    "        \n",
    "        results[key] = {\n",
    "            'good_mean': np.mean(good[key]),\n",
    "            'good_std': np.std(good[key]),\n",
    "            'bad_mean': np.mean(bad[key]),\n",
    "            'bad_std': np.std(bad[key]),\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'cohens_d': cohens_d,\n",
    "            'significant': p_value < 0.05\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run statistical tests\n",
    "stats_results = perform_statistical_tests(good_rewards, bad_rewards)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SANITY CHECK RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for key, result in stats_results.items():\n",
    "    status = \"✅ PASS\" if result['significant'] and result['cohens_d'] > 0 else \"❌ FAIL\"\n",
    "    print(f\"\\n{key.upper()} Reward:\")\n",
    "    print(f\"  Good: {result['good_mean']:.4f} ± {result['good_std']:.4f}\")\n",
    "    print(f\"  Bad:  {result['bad_mean']:.4f} ± {result['bad_std']:.4f}\")\n",
    "    print(f\"  p-value: {result['p_value']:.6f}\")\n",
    "    print(f\"  Cohen's d: {result['cohens_d']:.3f}\")\n",
    "    print(f\"  Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization: Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "reward_names = ['warp', 'epipolar', 'semantic', 'total']\n",
    "titles = ['R_warp (Depth Warping)', 'R_epi (Epipolar)', 'R_sem (Semantic)', 'R_total (Combined)']\n",
    "\n",
    "for ax, key, title in zip(axes.flat, reward_names, titles):\n",
    "    data = [good_rewards[key], bad_rewards[key]]\n",
    "    bp = ax.boxplot(data, labels=['Good', 'Bad'], patch_artist=True)\n",
    "    \n",
    "    # Color boxes\n",
    "    bp['boxes'][0].set_facecolor('lightgreen')\n",
    "    bp['boxes'][1].set_facecolor('lightcoral')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Reward Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add p-value annotation\n",
    "    p = stats_results[key]['p_value']\n",
    "    ax.annotate(f'p = {p:.4f}', xy=(0.95, 0.95), xycoords='axes fraction',\n",
    "                ha='right', va='top', fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Sanity Check: Reward Distribution for Good vs Bad Samples', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/sanity_check_boxplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for key in reward_names:\n",
    "    r = stats_results[key]\n",
    "    summary_data.append({\n",
    "        'Reward': key.capitalize(),\n",
    "        'Good (mean ± std)': f\"{r['good_mean']:.4f} ± {r['good_std']:.4f}\",\n",
    "        'Bad (mean ± std)': f\"{r['bad_mean']:.4f} ± {r['bad_std']:.4f}\",\n",
    "        't-statistic': f\"{r['t_stat']:.3f}\",\n",
    "        'p-value': f\"{r['p_value']:.6f}\",\n",
    "        \"Cohen's d\": f\"{r['cohens_d']:.3f}\",\n",
    "        'Verdict': '✅' if r['significant'] and r['cohens_d'] > 0.8 else '⚠️' if r['significant'] else '❌'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nSummary Table:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "**Criteria for proceeding to GRPO training:**\n",
    "- ✅ All reward components show statistically significant difference (p < 0.01)\n",
    "- ✅ Effect size (Cohen's d) > 0.8 for at least R_total\n",
    "\n",
    "If all criteria are met, the reward functions are validated for GRPO training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
