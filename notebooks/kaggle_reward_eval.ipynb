{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Zero-GRPO Reward Evaluation on Kaggle\n",
                "\n",
                "This notebook evaluates the multi-view consistency reward function using Ground Truth data rendered from Objaverse models via Blender.\n",
                "\n",
                "**Pre-requisites**:\n",
                "- Accelerator: GPU T4 x2 (recommended)\n",
                "- Internet: On"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone Repository\n",
                "!git clone https://github.com/kyrozepto/zero-grpo.git\n",
                "%cd zero-grpo\n",
                "# !git checkout your-branch-name  # Uncomment if needed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Dependencies\n",
                "!pip install -r requirements.txt\n",
                "!pip install kornia\n",
                "\n",
                "# Install Blender (Headless) for rendering GT\n",
                "!apt-get update\n",
                "!apt-get install blender -y"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Sample Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.makedirs(\"models\", exist_ok=True)\n",
                "\n",
                "# Download sample GLB files (Duck and DamagedHelmet from Khronos)\n",
                "!wget -O models/example_1.glb https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Models/master/2.0/Duck/glTF-Binary/Duck.glb\n",
                "!wget -O models/example_2.glb https://raw.githubusercontent.com/KhronosGroup/glTF-Sample-Models/master/2.0/DamagedHelmet/glTF-Binary/DamagedHelmet.glb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Render Ground Truth Images\n",
                "\n",
                "We use the custom Blender script to render 6 views matching Zero123++ v1.2 specifications (FoV 30, Elev 20/-10)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Render Object 1\n",
                "!blender --background --python scripts/render_zero123plus.py -- models/example_1.glb --output_dir data/gt/example_1\n",
                "\n",
                "# Render Object 2\n",
                "!blender --background --python scripts/render_zero123plus.py -- models/example_2.glb --output_dir data/gt/example_2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluate Rewards\n",
                "\n",
                "Run the `CompositeReward` on the generated images. We expect high scores (> 0.8) since these are perfect 3D consistency renders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import sys\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from torchvision import transforms\n",
                "\n",
                "# Ensure local modules are importable\n",
                "sys.path.append('.')\n",
                "from src.rewards import CompositeReward\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Initialize Reward Function\n",
                "reward_fn = CompositeReward(device=device)\n",
                "\n",
                "def load_views(path):\n",
                "    views = []\n",
                "    for i in range(6):\n",
                "        img_path = f\"{path}/{i:03d}.png\"\n",
                "        if not os.path.exists(img_path):\n",
                "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
                "        img = Image.open(img_path).convert('RGB')\n",
                "        views.append(transforms.ToTensor()(img))\n",
                "    # Stack and add batch dimension -> (1, 6, 3, H, W)\n",
                "    return torch.stack(views).unsqueeze(0).to(device)\n",
                "\n",
                "# List of paths to evaluate\n",
                "sample_paths = ['data/gt/example_1', 'data/gt/example_2']\n",
                "\n",
                "for path in sample_paths:\n",
                "    try:\n",
                "        images = load_views(path)\n",
                "        \n",
                "        # Use the first view as the 'conditioning' image\n",
                "        condition = images[:, 0]\n",
                "        \n",
                "        # Compute Rewards\n",
                "        # Step=10000 ensures maximum geometric weight (curriculum end)\n",
                "        with torch.no_grad():\n",
                "            results = reward_fn.forward(images, condition, step=10000)\n",
                "            \n",
                "        print(f\"\\nEvaluating: {path}\")\n",
                "        print(f\"Total Reward: {results['total'].item():.4f}\")\n",
                "        print(f\"  > Warp Score: {results['warp'].item():.4f}\")\n",
                "        print(f\"  > Epi Score:  {results['epipolar'].item():.4f}\")\n",
                "        print(f\"  > Sem Score:  {results['semantic'].item():.4f}\")\n",
                "        \n",
                "        # Visualization\n",
                "        fig, axes = plt.subplots(1, 6, figsize=(12, 2))\n",
                "        for i in range(6):\n",
                "            axes[i].imshow(images[0, i].cpu().permute(1, 2, 0))\n",
                "            axes[i].axis('off')\n",
                "        plt.suptitle(f\"{path} (R_total: {results['total'].item():.2f})\", fontsize=10)\n",
                "        plt.show()\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {path}: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
